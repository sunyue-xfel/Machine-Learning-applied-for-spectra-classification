{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cs231n.github.io/convolutional-networks/\n",
    "https://medium.com/apache-mxnet/multi-channel-convolutions-explained-with-ms-excel-9bbf8eb77108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import math\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "import matplotlib.style\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits import mplot3d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module comes in handy while writing many DL model. For example when you are trying to code Maxout Network as defined in the paper [Maxout Networks] (https://arxiv.org/pdf/1302.4389.pdf 44).\n",
    "https://github.com/pytorch/pytorch/commit/c7c8aaa7f040dd449dbc6aca9204b2f943aef477\n",
    "https://discuss.pytorch.org/t/multiple-parallel-fully-connected-layers-type-torch-cuda-floattensor-but-found-type-torch-floattensor/37810\n",
    "https://www.geeksforgeeks.org/single-neuron-neural-network-python/\n",
    "https://rhettinger.wordpress.com/2011/05/26/super-considered-super/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import glob, os, os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "import bisect\n",
    "import scipy.sparse as sparse  #for baseline subtraction\n",
    "from matplotlib import rc\n",
    "# rc('mathtext', default='regular')\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfont = {'fontname':'Helvetica'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Definitions'''\n",
    "\n",
    "def gaussian(x, x0, r, a, b):\n",
    "    y = b + a*np.exp(-(x-x0)**2/(2*r**2))\n",
    "    return y\n",
    "\n",
    "def PseudoVoigtFunction(WavNr, Pos, Amp, GammaL, FracL):\n",
    "    SigmaG = GammaL / np.sqrt(2*np.log(2)) # Calculate the sigma parameter  for the Gaussian distribution from GammaL (coupled in Pseudo-Voigt)\n",
    "    LorentzPart = Amp / np.pi * (GammaL / ((WavNr - Pos)**2 + GammaL**2)) # Lorentzian distribution\n",
    "    GaussPart = Amp / (np.sqrt(2*np.pi) * SigmaG) * np.exp( -(WavNr - Pos)**2 / (2 * SigmaG**2)) # Gaussian distribution\n",
    "    Fit = FracL * LorentzPart + (1 - FracL) * GaussPart # Linear combination of the two parts (or distributions)\n",
    "    return Fit\n",
    "\n",
    "#baseline subtraction based on Asymetric Least Square Smoothing\n",
    "#https://zanran_storage.s3.amazonaws.com/www.science.uva.nl/ContentPages/443199618.pdf\n",
    "def baseline_als(y, lam, p, niter=10):\n",
    "    L = len(y)\n",
    "    D = sparse.csc_matrix(np.diff(np.eye(L), 2))\n",
    "    w = np.ones(L)\n",
    "    for i in range(niter):\n",
    "        W = sparse.spdiags(w, 0, L, L)\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = sparse.linalg.spsolve(Z, w*y)\n",
    "        w = p * (y > z) + (1-p) * (y < z)\n",
    "    return z\n",
    "\n",
    "# Function which extracts the number of all XYfiles in the directory.    \n",
    "run_no=0\n",
    "def get_number_XYfiles(run_no):\n",
    "    directory = os.listdir('data/')\n",
    "    number_XYfiles = run_no\n",
    "    for Dir in directory:\n",
    "        number_XYfiles = number_XYfiles+1\n",
    "    return(number_XYfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "The number of XYfiles within the chosen run is: 350\n"
     ]
    }
   ],
   "source": [
    "# show the number of XYfiles found in the directory\n",
    "total_XYfiles = get_number_XYfiles(run_no)\n",
    "print(total_XYfiles)\n",
    "total_XYfiles=350 #[Pt=1084, MgFeOB1_263]\n",
    "print('The number of XYfiles within the chosen run is:', total_XYfiles)\n",
    "%pwd\n",
    "%mkdir -p ClassificationFigures\n",
    "save_figures_to = '../ClassificationFigures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/exfel/data/user/sunyue/Downloads/Brockhauser_Sandor/L2_Beamtime2019_Fe200culet_fe80mg20/XY\n"
     ]
    }
   ],
   "source": [
    "'''make sure that you have the right command directory selected'''\n",
    "%cd /gpfs/exfel/data/user/sunyue/Downloads/Brockhauser_Sandor/L2_Beamtime2019_Fe200culet_fe80mg20/XY/\n",
    "theta = [] \n",
    "I = []\n",
    "baseline = []\n",
    "Icorrect = []\n",
    "\n",
    "test_y=total_XYfiles-2\n",
    "for run_no in range(1,0+total_XYfiles):\n",
    "    fileNO = str(run_no).zfill(4) \n",
    "    fname = 'l2_fe80mg20_ramp_00001_m1_'+str(run_no).zfill(4)+'.xy'\n",
    "    thetas, Is = np.loadtxt(fname, skiprows=25, unpack=True) # reads all files in range and assigns 1st column to thetas and 2nd to Is\n",
    "    I.append(Is) # attaches a new array each time to a copy of previous, not really necessary here\n",
    "    idx1 = 0\n",
    "    idx2 = 4050\n",
    "#background subtraction\n",
    "#parameters lam and p have to be adjusted by hand!\n",
    "#try 10**2 < lam < 10**9\n",
    "#    0.001 <  p  < 0.1\n",
    "    lam = 100000\n",
    "    p = 0.002\n",
    "    baselines = baseline_als(Is[idx1:idx2], lam, p)\n",
    "    baseline.append(baselines)\n",
    "    Icorrected = Is[idx1:idx2] - baselines\n",
    "    Icorrect.append(Icorrected)\n",
    "#    if (run_no==15): \n",
    "#        print(thetas.size, Is.shape,type(I),np.shape(I),len(Icorrected),len(baselines),sep='\\n')\n",
    "    thetas = thetas[idx1:idx2]\n",
    "    theta.append(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta[0].shape,np.size(theta),len(theta),np.size(theta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "349*4023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(theta[98], I[98][idx1:idx2])\n",
    "plt.plot(theta[98], baseline[98],color = 'limegreen')\n",
    "plt.plot(theta[98], Icorrect[98], color = 'darkred')\n",
    "#plt.plot(theta[0], I[0], color = 'red')\n",
    "#plt.plot(theta[1500], I[1500][idx1:idx2])\n",
    "#plt.plot(theta[1500], baseline[1500])\n",
    "#plt.plot(theta[450], Icorrect[450], color = 'limegreen')\n",
    "#plt.plot(theta[420], I[420], color = 'limegreen')\n",
    "plt.ylabel('Intensity')#, fontsize = 12\n",
    "plt.xlabel('Diffraction angle 2$\\Theta$ (deg.)')#, fontsize = 12\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_plot_data(X, y, ai1=-1,ai2=1,bi1=-1,bi2=1,d=0, auto=False, zoom=1):\n",
    "    X = X.cpu()\n",
    "    y = y.cpu()\n",
    "#     plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=2, cmap=plt.cm.rainbow)\n",
    "    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=2, cmap=plt.cm.rainbow)\n",
    "#     plt.axis('square')\n",
    "#     plt.axis(np.array((ai1, ai2, bi1, bi2)) * zoom)\n",
    "#     if auto is True: plt.axis('equal')\n",
    "    plt.axis('on') \n",
    "    \n",
    "def minibatch_plot_model(mndinx1,mndinx2,mndiny1,mndiny2,X2, y2, model):\n",
    "    model.cpu()\n",
    "#     nx, ny = (200, 200)\n",
    "#     x = np.linspace(mndinx1, mndinx2, nx)\n",
    "#     y = np.linspace(mndiny1,mndiny2, ny)\n",
    "    x = np.arange(mndinx1, mndinx2, 0.02)\n",
    "    y = np.arange(mndiny1, mndiny2, 0.001)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(np.vstack((xx.reshape(-1), yy.reshape(-1))).T).float()\n",
    "        Z = model(data).detach()\n",
    "    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.rainbow, alpha=0.3)\n",
    "    minibatch_plot_data(X2, y2,mndinx1,mndinx2,mndiny1,mndiny2,zoom=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X, y, d=0, auto=False, zoom=1):\n",
    "    X = X.cpu()\n",
    "    y = y.cpu()\n",
    "#     plt.figure(figsize=(8,8))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_ylabel('Intensity')#, fontsize = 16,\n",
    "    ax.set_xlabel('Diffraction angle 2$\\Theta$ (deg.)')#, fontsize = 16\n",
    "#     plt.axis(np.array((axl, axr, byl, byh)) * zoom)\n",
    "    \n",
    "#     plt.rc('xtick',labelsize=16)\n",
    "#     plt.rc('ytick',labelsize=16)\n",
    "    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=0.6, cmap=plt.cm.rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(figsize=(8, 8)):\n",
    "#     plt.style.use(['dark_background', 'bmh'])\n",
    "#     plt.rc('figure', facecolor='none')\n",
    "    plt.rc('figure', figsize=figsize)\n",
    "    \n",
    "def yue_plot_data(X, y, axl,axr,byl,byh,d=0, auto=False, zoom=1):\n",
    "    X = X.cpu()\n",
    "    y = y.cpu()\n",
    "#     plt.figure(figsize=(8,8))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_ylabel('Intensity')#, fontsize = 16,\n",
    "    ax.set_xlabel('Diffraction angle 2$\\Theta$ (deg.)')#, fontsize = 16\n",
    "    plt.axis(np.array((axl, axr, byl, byh)) * zoom)\n",
    "    #ax.set_ylim(-2,50)\n",
    "    #ax.set_xlim(9.5,26)\n",
    "    \n",
    "#     plt.rc('xtick',labelsize=16)\n",
    "#     plt.rc('ytick',labelsize=16)\n",
    "    plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], c=y, s=0.6, cmap=plt.cm.rainbow)\n",
    "    #plt.axis('auto')      \n",
    "#     ax.spines['right'].set_visible(False) #remove right axis spine\n",
    "#     ax.spines['top'].set_visible(False) # remove top axis spine  \n",
    "    \n",
    "    \"\"\"\n",
    "    X = X.cpu()\n",
    "    y = y.cpu()\n",
    "    plt.axis(np.array((axl, axr, byl, byh)) * zoom)\n",
    "    if auto is True: plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #_m, _c = 0, '.15'\n",
    "    #plt.axvline(0, ymin=_m, color=_c, lw=1, zorder=0)\n",
    "    #plt.axhline(0, xmin=_m, color=_c, lw=1, zorder=0)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    cmaps = [('Perceptually Uniform Sequential', [\n",
    "                'viridis', 'plasma', 'inferno', 'magma', 'cividis']),\n",
    "             ('Sequential', [\n",
    "                'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
    "                'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
    "                'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']),\n",
    "             ('Sequential (2)', [\n",
    "                'binary', 'gist_yarg', 'gist_gray', 'gray', 'bone', 'pink',\n",
    "                'spring', 'summer', 'autumn', 'winter', 'cool', 'Wistia',\n",
    "                'hot', 'afmhot', 'gist_heat', 'copper']),\n",
    "             ('Diverging', [\n",
    "                'PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu',\n",
    "                'RdYlBu', 'RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic']),\n",
    "             ('Cyclic', ['twilight', 'twilight_shifted', 'hsv']),\n",
    "             ('Qualitative', [\n",
    "                'Pastel1', 'Pastel2', 'Paired', 'Accent',\n",
    "                'Dark2', 'Set1', 'Set2', 'Set3',\n",
    "                'tab10', 'tab20', 'tab20b', 'tab20c']),\n",
    "             ('Miscellaneous', [\n",
    "                'flag', 'prism', 'ocean', 'gist_earth', 'terrain', 'gist_stern',\n",
    "                'gnuplot', 'gnuplot2', 'CMRmap', 'cubehelix', 'brg',\n",
    "                'gist_rainbow', 'rainbow', 'jet', 'nipy_spectral', 'gist_ncar'])]\n",
    "    \"\"\"\n",
    "\n",
    "def ys_plot_model(X, y, model):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    bx = plt.subplot(111)\n",
    "    plt.axis([axl, axr, byl, byh])\n",
    "    \n",
    "#     plt.rc('xtick',labelsize=16)\n",
    "#     plt.rc('ytick',labelsize=16)\n",
    "    \n",
    "    model.cpu()\n",
    "    X=X.cpu()\n",
    "    mesh1 = np.arange(axl, axr, 0.01)\n",
    "    mesh2 = np.arange(byl, byh, 0.01)\n",
    "    xx, yy = np.meshgrid(mesh1, mesh2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(np.vstack((xx.reshape(-1), yy.reshape(-1))).T).float().cpu()\n",
    "        Z = model(data).detach()\n",
    "        #print(xx,Z.shape,Zt,data.shape)\n",
    "    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.rainbow, alpha=0.3)     \n",
    "    yue_plot_data(X, y, axl,axr,byl,byh)\n",
    "    \n",
    "    \n",
    "def yue_plot_3D(X, X_axis):\n",
    "    X = X.cpu()\n",
    "    X_axis = X_axis.cpu()    \n",
    "    \n",
    "    fig = plt.figure(figsize = (10, 7)) \n",
    "    ax = plt.axes(projection =\"3d\") \n",
    "\n",
    "    # Creating plot \n",
    "    ax.scatter3D(X_axis.numpy(), X.numpy()[:, 0], X.numpy()[:, 1],s=0.3, color = \"green\"); \n",
    "    \n",
    "    plt.title(\"Spectra 3D scatter plot\") \n",
    "    ax.set_xlabel('X-axis') # , fontweight ='bold'\n",
    "    ax.set_ylabel('angle')  #, fontweight ='bold'\n",
    "    ax.set_zlabel('intensity') #, fontweight ='bold'\n",
    "\n",
    "    # show plot \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data for training\n",
    "#plotting various plots to show development of bcc -> hcp transition\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# plt.rc('xtick',labelsize=16)\n",
    "# plt.rc('ytick',labelsize=16)\n",
    "\n",
    "# These are the colors that will be used in the plot\n",
    "color_sequence = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c',\n",
    "                  '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',\n",
    "                  '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f',\n",
    "                  '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "N=len(theta[0])\n",
    "\n",
    "X_1 = []# training: theta\n",
    "X_2 = []# training: intensity\n",
    "y   = []\n",
    "global Ci,Ci_0,div_num,gap #indicates num of curves, and curves of class0.\n",
    "div_num = 185 #indicates the boundary of spectral curves.\n",
    "gap = 1 #20\n",
    "Ci = 0  \n",
    "Ci_0 = 0\n",
    "X_axis=[] # used to store data for 3D plotting\n",
    "\n",
    "for pct in range(0,total_XYfiles-1,gap):\n",
    "    #ax.plot(theta[pct], Icorrect[pct]+6-pct/50., color = 'limegreen' if pct <200 else 'blue')\n",
    "    #ax.plot(theta[pct], Icorrect[pct]+6-pct/50., color = color_sequence[Ci])\n",
    "#     ax.plot(theta[pct], Icorrect[pct]+6-pct/50.,lw=1)\n",
    "    ax.plot(theta[pct], Icorrect[pct],lw=0.6)\n",
    " \n",
    "    #testX = torch.FloatTensor(theta[pct])\n",
    "    #testX = torch.cat((testX),1)\n",
    "    \n",
    "    Icorrect_t = Icorrect[pct]\n",
    "#     Icorrect_t = Icorrect[pct]+6-pct/50.\n",
    "    theta_t = theta[pct]\n",
    "    X_1.append(theta_t)\n",
    "    X_2.append(Icorrect_t)\n",
    "    X_axis.append(np.ones(N)*pct) \n",
    "    \n",
    "    Ci += 1\n",
    "    if pct <div_num:\n",
    "        Ci_0 += 1\n",
    "    #y.append(torch.zeros(1,size(theta[pct])) if pct < 200 else torch.ones(1,size(theta[pct]))\n",
    "\n",
    "             \n",
    "print(X_1[0].shape,Ci,Ci_0)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Intensity')#, fontsize = 16,\n",
    "ax.set_xlabel('Diffraction angle 2$\\Theta$ (deg.)')#, fontsize = 16\n",
    "# ax.set_ylim(-2,45)\n",
    "ax.set_xlim(9.5,26)\n",
    "\n",
    "plt.title('[Fe10,Mg90]O 5s ramp, 100 ms exposure')#, fontsize=16, fontweight='bold'\n",
    "\n",
    "# ax.spines['right'].set_visible(False) #remove right axis spine\n",
    "# ax.spines['top'].set_visible(False) # remove top axis spine\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_figures_to+\"Original data used for training.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.size(X_1)), len(X_1), 349*4023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting spectra in another way\n",
    "plt.figure(figsize=(8,8))\n",
    "# plt.rc('xtick',labelsize=16)\n",
    "# plt.rc('ytick',labelsize=16)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "t_gap=20 # this parameter decide the number of spectral curves for test.\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "colors = cm.brg(np.linspace(0, 1, len(range(0,total_XYfiles-1,t_gap)))) # or gist_rainbow\n",
    "\n",
    "pos_d=0\n",
    "for pct,cc in zip(range(0,total_XYfiles-1,t_gap),colors):\n",
    "    pct = pct+pos_d\n",
    "    plt.scatter(theta[pct], Icorrect[pct], color=cc,s=0.3)\n",
    "    \n",
    "ax.set_ylabel('Intensity')\n",
    "ax.set_xlabel('Diffraction angle 2$\\Theta$ (deg.)')\n",
    "ax.set_ylim(-2,50)\n",
    "ax.set_xlim(9.5,26)\n",
    "plt.grid(True)\n",
    "plt.title('[Fe10,Mg90]O 5s ramp, 100 ms exposure')#, fontsize=16, fontweight='bold'\n",
    "plt.savefig(save_figures_to+\"Spectra data for testing (manually classified).png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# # X = sc.fit(X_2)\n",
    "# X_i = sc.fit_transform(X_2)\n",
    "# # X_train = sc.fit_transform(X_2)\n",
    "# # X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_flag = 0\n",
    "if standard_flag:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_i = sc.fit_transform(X_2)\n",
    "    # X = sc.fit(X_2)\n",
    "    # X_train = sc.fit_transform(X_2)\n",
    "    # X_test = sc.transform(X_test)\n",
    "else:\n",
    "    X_i = X_2 - np.mean(X_2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_i.mean(axis=0))\n",
    "print(X_i.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_NUM_COMP = len(X_i)-1\n",
    "print(PCA_NUM_COMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "Sum_Explained_variance =.99\n",
    "pca = PCA(Sum_Explained_variance)\n",
    "# pca = PCA(n_components=240)\n",
    "X2_data =pca.fit_transform(X_i)\n",
    "# X2_test = pca.transform(X_test)\n",
    "N_Compents=pca.n_components_ \n",
    "print(X2_data.shape)\n",
    "print(N_Compents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_),'o-')\n",
    "plt.xlabel('number of components');\n",
    "plt.ylim(0,1.0)\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(X2_data,'.-')\n",
    "plt.xlabel('number of components');\n",
    "print(X2_data.shape)\n",
    "plt.figure(figsize=(6,6))\n",
    "print(X2_data[-3:-1].shape)\n",
    "plt.plot(X2_data[100],'.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick certern extreme curves and add some random noise to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = N_Compents\n",
    "\n",
    "# p_num=[0,32 ,8,26, 14,30, 2,34, 3,31, 4,21, 10,23, 5,22, 7,27, 15,28, 16,29, 9,24] \n",
    "p_num_c0= [i for i in range(16)] #[0,2,4,5,7,8,10,15] #1 #5  class 0 class 1 class 0\n",
    "p_num_c1= [i for i in np.arange(22,34)] #[22,24,28,30,32,34] #1 #5  class 0 class 1 class 0\n",
    "p_num = p_num_c0 + p_num_c1\n",
    "print(p_num,len(p_num_c1))\n",
    "N_TrainOrg = len(p_num)\n",
    "Train_Gap = 10\n",
    "X_2=torch.FloatTensor(X2_data)\n",
    "Xtemp = torch.zeros(len(p_num),N_Compents)\n",
    "X_Extrem_tmp = torch.empty(0,N_Compents)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for i in range(len(p_num)):\n",
    "    Xtemp[i] = X_2[Train_Gap*p_num[i]] # intensity\n",
    "    ax.plot(Xtemp[i,1:20]-i*7,lw=0.6,color='red' if Train_Gap*p_num[i]<185 else 'blue')\n",
    "    print(X_Extrem_tmp.shape,Xtemp[i].shape)\n",
    "    X_Extrem_tmp=torch.cat((X_Extrem_tmp,torch.reshape(Xtemp[i],(1,-1))),0)\n",
    "print(Xtemp.shape)\n",
    "\n",
    "X_Extrem= torch.empty(0,N_Compents)\n",
    "X_Extrem    =torch.cat((X_Extrem,X_Extrem_tmp),0) #  spectral curve are stacked in one column.\n",
    "\n",
    "\n",
    "N_sim=100 # number of simulated spectra for each original ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "N = N_Compents\n",
    "\n",
    "# p_num=[0,32 ,8,26, 14,30, 2,34, 3,31, 4,21, 10,23, 5,22, 7,27, 15,28, 16,29, 9,24] \n",
    "# p_num_c0= [i for i in np.arange(1,16)] #[0,2,4,5,7,8,10,15] #1 #5  class 0 class 1 class 0\n",
    "p_num_c0= [i for i in range(16)] #[0,2,4,5,7,8,10,15] #1 #5  class 0 class 1 class 0\n",
    "p_num_c1= [i for i in np.arange(22,34)] #[22,24,28,30,32,34] #1 #5  class 0 class 1 class 0\n",
    "p_num = p_num_c0 + p_num_c1\n",
    "print(p_num, len(p_num_c0),len(p_num_c1))\n",
    "N_TrainOrg = len(p_num)\n",
    "Train_Gap = 10\n",
    "X_2=torch.FloatTensor(X2_data)\n",
    "Xtemp = torch.zeros(len(p_num),N_Compents)\n",
    "X_Extrem_tmp = torch.empty(0,N_Compents)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for i in range(len(p_num)):\n",
    "    Xtemp[i] = X_2[Train_Gap*p_num[i]] # intensity\n",
    "    if i==0: \n",
    "        ax.plot(Xtemp[i],lw=0.6,color='red' if i< len(p_num_c0) else 'blue', label='Class 0')#\n",
    "    elif i==len(p_num)-1:\n",
    "        ax.plot(Xtemp[i],lw=0.6,color='red' if i< len(p_num_c0) else 'blue', label='Class 1')#\n",
    "    else:\n",
    "        ax.plot(Xtemp[i],lw=0.6,color='red' if i< len(p_num_c0) else 'blue')\n",
    "        \n",
    "    print(X_Extrem_tmp.shape,Xtemp[i].shape)\n",
    "    X_Extrem_tmp=torch.cat((X_Extrem_tmp,torch.reshape(Xtemp[i],(1,-1))),0)\n",
    "print(Xtemp.shape)\n",
    "\n",
    "X_Extrem= torch.empty(0,N_Compents)\n",
    "X_Extrem    =torch.cat((X_Extrem,X_Extrem_tmp),0) #  spectral curve are stacked in one column.\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# ax = plt.subplot(111)\n",
    "# ax.plot(X_Extrem[0],lw=0.6,color='red')\n",
    "# ax.plot(X_Extrem[-1],lw=0.6,color='blue')\n",
    "\n",
    "N_sim=100 # number of simulated spectra for each original ones\n",
    "\n",
    "for n in range(N_sim):\n",
    "    X_Extrem_tmp = torch.empty(0,N_Compents)\n",
    "    seed = n*1000\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    for j in range(len(p_num)):\n",
    "        for i in range(N_Compents):\n",
    "            Xtemp[j,i] = Xtemp[j,i] +random.random()/12\n",
    "        ax.plot(Xtemp[j],lw=0.6,color='red' if j< len(p_num_c0) else 'blue')\n",
    "        X_Extrem_tmp=torch.cat((X_Extrem_tmp,torch.reshape(Xtemp[j],(1,-1))),0)\n",
    "    X_Extrem    =torch.cat((X_Extrem,X_Extrem_tmp),0) #  spectral curve are stacked in one column.\n",
    "#     y_Extrem_tmp=torch.cat((ytemp1,ytemp2),0)\n",
    "#     y_Extrem    =torch.cat((y_Extrem,y_Extrem_tmp),0)\n",
    "# one row for one spectral curve:\n",
    "print((X_Extrem).shape)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "N_Train=N_TrainOrg*N_sim+N_TrainOrg\n",
    "\n",
    "plt.xlabel('PCs');\n",
    "plt.ylabel('intensity (after PCA processing)');\n",
    "plt.title('Training dataset');\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(save_figures_to+\"Training dataset.svg\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "#  ===============================method 2============================\n",
    "global X2,y2  \n",
    "X2 = X_Extrem.to(device)\n",
    "y2_orig = torch.cat((torch.zeros(len(p_num_c0),1),torch.ones(len(p_num_c1),1)),0)\n",
    "y2 = torch.empty(0)\n",
    "for n in range((N_sim+1)):\n",
    "    y2= torch.cat([y2, y2_orig], dim=0) \n",
    "\n",
    "y2 = torch.reshape(y2,(-1,1)).to(device)\n",
    "print(X2.shape,y2.shape,type(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training data selected in the original dataset.\n",
    "\n",
    "N_orig = len(theta[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "# plt.rc('xtick') #,labelsize=16\n",
    "# plt.rc('ytick') #,labelsize=16\n",
    "\n",
    "# These are the colors that will be used in the plot\n",
    "color_sequence = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c',\n",
    "                  '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',\n",
    "                  '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f',\n",
    "                  '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "\n",
    "# X_1 = []# training: theta\n",
    "# X_2 = []# training: intensity\n",
    "y   = []\n",
    "global Ci,Ci_0,div_num,gap #indicates num of curves, and curves of class0.\n",
    "div_num = 185 #indicates the boundary of spectral curves.\n",
    "gap = 10\n",
    "# Ci = 0  \n",
    "# Ci_0 = 0\n",
    "for pct in range(0,total_XYfiles,gap):\n",
    "    shift = 12-pct/5.\n",
    "    ax.plot(theta[pct][0:N_orig], Icorrect[pct][0:N_orig]+shift, color = 'red' if ((pct in [gap*l for l in p_num_c0])) else ('blue' if (pct in [gap*l for l in p_num_c1]) else 'limegreen')  ,lw=0.6)\n",
    "    Ci += 1\n",
    "    if pct <div_num:\n",
    "        Ci_0 += 1\n",
    "    \n",
    "    Icorrect_t = Icorrect[pct]\n",
    "    theta_t = theta[pct]\n",
    "#     X_1.append(theta_t[0:N_orig])\n",
    "#     X_2.append(Icorrect_t[0:N_orig])\n",
    "    if not pct % 20:\n",
    "        ax.text(theta_t[int(2*N_orig/3)], Icorrect_t[int(2*N_orig/3)]+shift, \"n = %i\" % (pct) , size=6, ha=\"center\", color=\"k\")\n",
    "             \n",
    "# print(X_1[0].shape,Ci,Ci_0)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Intensity', )\n",
    "ax.set_xlabel('Diffraction angle 2$\\Theta$ (deg.)',)\n",
    "ax.set_xlim(9.5,26)\n",
    "plt.grid(True)\n",
    "plt.title('[Mg0.2,Fe0.8] 50s ramp, 100 ms exposure') #,  fontweight='bold'\n",
    "ax.get_yaxis().set_ticks([])\n",
    "# plt.rc('xtick',labelsize=6)\n",
    "# plt.rc('ytick',labelsize=16)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(save_figures_to+\"Original data used for training.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \"\"\"\n",
    "# N = N_Compents\n",
    "\n",
    "# # p_num=[0,32 ,8,26, 14,30, 2,34, 3,31, 4,21, 10,23, 5,22, 7,27, 15,28, 16,29, 9,24] \n",
    "# p_num=[0,32 ,8,26, 14,30, 2,34, 3,31, 4,21, 10,23, 5,22, 7,27, 15,28] #1 #5  class 0 class 1 class 0\n",
    "# N_TrainOrg = len(p_num)\n",
    "# Train_Gap = 10\n",
    "# X_2=torch.FloatTensor(X2_data)\n",
    "# Xtemp = torch.zeros(len(p_num),N_Compents)\n",
    "# X_Extrem_tmp = torch.empty(0,N_Compents)\n",
    "# for i in range(len(p_num)):\n",
    "#     Xtemp[i] = X_2[Train_Gap*p_num[i]] # intensity\n",
    "#     print(X_Extrem_tmp.shape,Xtemp[i].shape)\n",
    "#     X_Extrem_tmp=torch.cat((X_Extrem_tmp,torch.reshape(Xtemp[i],(1,-1))),0)\n",
    "# print(Xtemp.shape)\n",
    "\n",
    "# X_Extrem= torch.empty(0,N_Compents)\n",
    "# X_Extrem    =torch.cat((X_Extrem,X_Extrem_tmp),0) #  spectral curve are stacked in one column.\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# ax = plt.subplot(111)\n",
    "# ax.plot(Xtemp[0],lw=0.6,color='red')\n",
    "# ax.plot(Xtemp[2],lw=0.6,color='blue')\n",
    "# N_sim=200 # simulated spectra \n",
    "\n",
    "# for n in range(N_sim):\n",
    "#     X_Extrem_tmp = torch.empty(0,N_Compents)\n",
    "#     seed = n*1000\n",
    "#     random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     for j in range(len(p_num)):\n",
    "#         for i in range(N_Compents):\n",
    "#             Xtemp[j,i] = Xtemp[j,i] +random.random()/12\n",
    "#         ax.plot(Xtemp[j],lw=0.6,color='red' if j/2==0 else 'blue')\n",
    "#         X_Extrem_tmp=torch.cat((X_Extrem_tmp,torch.reshape(Xtemp[j],(1,-1))),0)\n",
    "#     X_Extrem    =torch.cat((X_Extrem,X_Extrem_tmp),0) #  spectral curve are stacked in one column.\n",
    "# #     y_Extrem_tmp=torch.cat((ytemp1,ytemp2),0)\n",
    "# #     y_Extrem    =torch.cat((y_Extrem,y_Extrem_tmp),0)\n",
    "# # one row for one spectral curve:\n",
    "# print((X_Extrem).shape)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### ====================assign labels to training set============================\n",
    "# N_Train=N_TrainOrg*N_sim+N_TrainOrg\n",
    "# global X2,y2  \n",
    "# X2 = X_Extrem.to(device)\n",
    "# # y2 = torch.FloatTensor([0, 1] * (N_sim+int(N_TrainOrg/2))).to(device)\n",
    "# y2 = torch.FloatTensor([0, 1] * (int(N_Train/2))).to(device)\n",
    "# y2 = torch.reshape(y2,(-1,1))\n",
    "# print(X2.shape,y2.shape,type(y2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(theta_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data for testing\n",
    "global X2t,yt\n",
    "print(X_2.shape)\n",
    "Full_flag = 1 # 1 means all dataset are used for testing, 0 means subtracted training data.\n",
    "if Full_flag:\n",
    "    X2t=X_2.to(device) # only use intensity information\n",
    "else:\n",
    "    Train_num = [Train_Gap*l for l in p_num];\n",
    "#     print('Train_num:',Train_num)\n",
    "    full_n = [i for i in range(len(X_2))]\n",
    "    test_n = [x for x in full_n if (x not in Train_num)]\n",
    "#     print('Test_num:',test_n)\n",
    "    X2t = X_2[test_n,:].to(device)\n",
    "    print('Test dataset:',X2t.shape)\n",
    "    Ntn = Ntn-len(Train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "N = N_Compents\n",
    "# N = np.size(theta[0])  # num_samples_per_class\n",
    "D = 2  # dimensions\n",
    "C = 2  # num_classes\n",
    "H = 5 # num_hidden_units\n",
    "B = 33 # num_bins\n",
    "S = 0 #bin id\n",
    "# Ntn= 2 # num_test_classes\n",
    "Si=0\n",
    "iternum= 45 if not standard_flag else 15\n",
    "n_feature =20\n",
    "\n",
    "global N_Train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Conv1d() applies 1D convolution over the input. nn.Conv1d() expects the input to be of the shape [batch_size, input_channels, signal_length] .\n",
    "Conv1d — Input 2d\n",
    "To apply 1D convolution on a 2d input signal, we can do the following. First, we define our input tensor of the size [1, 2, 5] where batch_size = 1, input_channels = 2 , and signal_length = 5 .\n",
    "\n",
    "\n",
    "You are forgetting the \"minibatch dimension\", each \"1D\" sample has indeed two dimensions: the number of channels (7 in your example) and length (10 in your case). However, pytorch expects as input not a single sample, but rather a minibatch of B samples stacked together along the \"minibatch dimension\".\n",
    "So a \"1D\" CNN in pytorch expects a 3D tensor as input: BxCxT. If you only have one signal, you can add a singleton dimension:\n",
    "\n",
    " out = model(torch.tensor(X)[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=N_Compents,  num_layers=1, hidden_size=128, O_feature=1, BinNum = B):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        #(seq_len, batch, input_size)\n",
    " \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, O_feature),          \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "        self._create_weights()\n",
    "        \n",
    "\n",
    "#=======================================================================\n",
    "#=======================================================================\n",
    "    def _create_weights(self, mean=0.0, std=0.05):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data.normal_(mean, std) \n",
    "\n",
    "#=======================================================================\n",
    "#=======================================================================\n",
    "\n",
    "    def forward(self, x):\n",
    "        In_Lstm = x\n",
    "#         In_Lstm = torch.reshape(In_Lstm,(-1,1,N))\n",
    "        In_Lstm = torch.reshape(In_Lstm,(-1,1,self.input_size))\n",
    "        # In_Lstm--> (batch, seq_len=1, input_size) as batch first;\n",
    "        h0 = torch.zeros(self.num_layers, In_Lstm.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, In_Lstm.size(0), self.hidden_size).to(device)\n",
    "        # h0, c0 --> (num_layers, batch_size, hidden_size)\n",
    "        out, _  = self.lstm(In_Lstm,(h0, c0))\n",
    "        # out --> (batch_size, sequence_len, hidden_size)\n",
    "        out  = out[:, -1, :]\n",
    "        out  = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "      \n",
    "# NUM_LAYERS=3 #2\n",
    "# H_SIZE =256 \n",
    "\n",
    "NUM_LAYERS= 1 if not standard_flag else 3\n",
    "H_SIZE = 64 if not standard_flag else 256\n",
    "\n",
    "O_FeatCOV=1 #num of classes\n",
    "model = LSTM(\n",
    "    input_size = int(N_Compents),\n",
    "    num_layers = NUM_LAYERS,\n",
    "    hidden_size = H_SIZE,\n",
    "    O_feature=O_FeatCOV,\n",
    "    BinNum = B\n",
    ")\n",
    "model.to(device)\n",
    "# x = torch.randn(BATCH_SIZE, IN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(N_Compents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name,type(param), param.size())\n",
    "\n",
    "# H_SIZE*4 (input gate, forget, )\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('pytorch_total_params:',pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick two extreme curves for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y2.t(),y2.shape,len(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NN in each bin\n",
    "def TrainingProc():\n",
    "    global X2,y2\n",
    "#     X2 = torch.zeros(N2 * N_Train, D*B).to(device)\n",
    "#     y2 = torch.zeros(N2 * N_Train, 1, dtype=torch.float).to(device)    \n",
    "    \n",
    "#     for b in range(B):\n",
    "#         for ix in range(N2):\n",
    "#             for ic in range(N_Train):\n",
    "#                 X2[ix+ic*N2,2*b:2*b+2] = X_Extrem[b*N2+ix+ic*N]\n",
    "#                 y2[ix+ic*N2] = y_Extrem[b*N2+ix+ic*N]\n",
    "    #print(\"X2:\", tuple(X2.size()))\n",
    "    #print(\"y2:\", tuple(y2.size()))\n",
    "    #print('y2.shape',y2.shape)\n",
    "    \n",
    "    learning_rate = 2e-3  # 8e-3\n",
    "    lambda_l2 = 2e-5\n",
    "    # nn package to create our linear model\n",
    "    # each Linear module has a weight and bias\n",
    "\n",
    "#     model = nn.Sequential(\n",
    "#         nn.Linear(D*B, H),\n",
    "#         nn.ReLU(),\n",
    "\n",
    "# #         nn.Linear(H, int(H/C)),\n",
    "# #         nn.ReLU(),\n",
    "# #         nn.Linear(H, C),\n",
    "# #         nn.ReLU(),\n",
    "#         nn.Linear(H, 1),\n",
    "#         nn.Sigmoid()\n",
    "#     )\n",
    "#     model.to(device)\n",
    "\n",
    "    # nn package also has different loss functions.\n",
    "    # we use cross entropy loss for our classification task\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    # we use the optim package to apply\n",
    "    # ADAM for our parameter updates\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2) # built-in L2\n",
    "    #optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate, betas=(0.8, 0.999), eps=1e-08, weight_decay=0) # built-in L2\n",
    "\n",
    "    # e = 1.  # plotting purpose\n",
    "\n",
    "    # Training\n",
    "    dh=display.display(\"Training\",display_id=True)\n",
    "    for t in range(iternum):\n",
    "        # Feed forward to get the logits\n",
    "        y_pred = model(X2)\n",
    "#         y_pred = model(X_Extrem_x,X_Extrem_y)\n",
    "#         print(y_pred.shape)\n",
    "        # Compute the loss and accuracy\n",
    "        loss = criterion(y_pred, y2)\n",
    "        predicted = y_pred > 0.5\n",
    "#         print(y2,predicted)\n",
    "        acc = (y2 == predicted).sum().float() / len(y2)\n",
    "        dh.update(\" [EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % ( t, loss.item(), acc))\n",
    "        #display.clear_output(wait=True)\n",
    "              \n",
    "        # zero the gradients before running\n",
    "        # the backward pass.\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Backward pass to compute the gradient\n",
    "        # of loss w.r.t our learnable params. \n",
    "        loss.backward()\n",
    "    \n",
    "        # Update params\n",
    "        optimizer.step()\n",
    "        \n",
    "    #print(len(y2),y_pred.size(),loss,sep='\\n') \n",
    "    return acc\n",
    "#     return acc,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pick two extreme curves for training and generate test data in each bin\n",
    "global Acc,N2\n",
    "N2=int(N/B)\n",
    "ytest_pred=[]\n",
    "# print(y2.t())\n",
    "# ====================training=======================\n",
    "from time import time\n",
    "t0= time()\n",
    "Acc =TrainingProc()  \n",
    "t1= time()\n",
    "print(\"training done in %0.3fs\" % (t1 - t0))\n",
    "with torch.no_grad(): \n",
    "    y_pred= model(X2) # \n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    y_pred= model(X2) # \n",
    "y_pred = y_pred>0.5\n",
    "#     y_pred = model(X_Extrem_x,X_Extrem_y)\n",
    "\n",
    "print(y_pred[0:10].t(),y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X2t.shape,X2.shape)\n",
    "print(X2.shape,X2t.shape,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad(): \n",
    "    y2t = model(X2t)# use model in each bin to predict label of test data curves belong to each bin             \n",
    "y2t_pred = y2t>0.5 \n",
    "y2t_pred = torch.squeeze(y2t_pred)\n",
    "# FinlPredLabel =y2t_pred.cpu().numpy().astype(int)\n",
    "FinlPredLabel =1*y2t_pred.cpu()\n",
    "print(y2t_pred.shape)\n",
    "\n",
    "print(FinlPredLabel.shape,FinlPredLabel)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve-wise ambigious region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    var_C0=0 # initial value of class 0;\n",
    "    Ntn=y2t_pred.shape[0]\n",
    "    for j in range(Ntn-1): # test data sets(curves)    \n",
    "        if (FinlPredLabel[j] == 0) and (FinlPredLabel[(j+1)]==0):\n",
    "            var_C0 = j+1\n",
    "        else:\n",
    "            break  \n",
    "    var_C1=Ntn-1 # initial value of class 1; So after iteration, if var_C1=Ntn-1(still this value), it means the following conditions are not met.\n",
    "    for j in range(Ntn-1,0,-1): # test data sets(curves)   \n",
    "        if (FinlPredLabel[j] == 1) and (FinlPredLabel[(j-1)]==1):\n",
    "            var_C1 = j-1\n",
    "        else:\n",
    "            break\n",
    "    torch.set_printoptions(threshold=10_000)\n",
    "    np.set_printoptions(threshold=10_000)\n",
    "     \n",
    "    if var_C0==Ntn-1:\n",
    "        Glo_acc = 0.50\n",
    "        print(\"Interval with low classification confidence is (%i ,  %i)\" % (var_C0,  var_C1))\n",
    "        print(\"The boundary is not found  and all curves are labeled as 0.\")\n",
    "    elif var_C1==0:\n",
    "        Glo_acc = 0.50\n",
    "        print(\"Interval with low classification confidence is (%i ,  %i)\" % (var_C0,  var_C1))\n",
    "        print(\"The boundary is not found and all curves are labeled as 1.\")\n",
    "    elif var_C0==0 and var_C1==Ntn-1:\n",
    "        Glo_acc = 0.00\n",
    "        print(\"Interval with low classification confidence is (%i ,  %i)\" % (var_C0,  var_C1))\n",
    "        print(\"The boundary is not found  and all curves are labeled as 1.\" )\n",
    "    else:\n",
    "        Glo_acc = 1-float((var_C1-var_C0-1)/Ntn)\n",
    "        print(\"Interval with low classification confidence is (%i ,  %i)\" % (var_C0,  var_C1))\n",
    "        print(\"Overall classification accuracy is %.3f\" % (Glo_acc*100)+\"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(FinlPredLabel[p0_num*gap])\n",
    "# print(FinlPredLabel[p_num*gap])\n",
    "print(FinlPredLabel[p_num[0]*Train_Gap])\n",
    "print(FinlPredLabel[p_num[1]*Train_Gap])\n",
    "print(FinlPredLabel[p_num[2]*Train_Gap])\n",
    "print(FinlPredLabel[p_num[3]*Train_Gap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
